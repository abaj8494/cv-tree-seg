\relax 
\providecommand{\transparent@use}[1]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{b1}
\citation{b2}
\citation{b2}
\citation{b3}
\citation{b29}
\citation{b4}
\citation{b1}
\citation{b5}
\citation{b2}
\citation{b6}
\citation{b6}
\citation{b7}
\citation{b6}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {II}Literature Review}{1}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {III}Methods}{1}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-A}}DeepLabV3\,+CBAM for Fine–Grained Semantic Segmentation}{1}{subsection.3.1}\protected@file@percent }
\newlabel{sec:seg_deeplab_cbam}{{\mbox  {III-A}}{1}{DeepLabV3\,+CBAM for Fine–Grained Semantic Segmentation}{subsection.3.1}{}}
\citation{b8}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces CBAM: sequential \emph  {channel} (\(M_c\)) and \emph  {spatial} (\(M_s\)) attention. Adapted from}}{2}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:cbam}{{1}{2}{CBAM: sequential \emph {channel} (\(M_c\)) and \emph {spatial} (\(M_s\)) attention. Adapted from}{figure.caption.1}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-A}0a}Motivation.}{2}{paragraph.3.1.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-A}0b}Pre-processing.}{2}{paragraph.3.1.0.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-A}0c}Encoder with embedded attention.}{2}{paragraph.3.1.0.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-A}0d}Attention mechanism.}{2}{paragraph.3.1.0.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Encoder–decoder topology of DeepLabV3\,+. Atrous rates \(\{1,6,12,18\}\) provide multi–scale context; a skip connection injects low-level detail for sharp boundaries.}}{2}{figure.caption.2}\protected@file@percent }
\newlabel{fig:deeplabv3p}{{2}{2}{Encoder–decoder topology of DeepLabV3\,+. Atrous rates \(\{1,6,12,18\}\) provide multi–scale context; a skip connection injects low-level detail for sharp boundaries}{figure.caption.2}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-A}0e}Atrous Spatial Pyramid Pooling.}{2}{paragraph.3.1.0.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-A}0f}Decoder.}{2}{paragraph.3.1.0.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-A}0g}Loss and optimisation.}{2}{paragraph.3.1.0.7}\protected@file@percent }
\citation{b9}
\citation{b10}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-B}}CNN}{3}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-C}}Random Forests}{3}{subsection.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Random forest classifier}}{3}{figure.caption.3}\protected@file@percent }
\newlabel{fig:placeholder}{{3}{3}{Random forest classifier}{figure.caption.3}{}}
\citation{b11}
\citation{b12}
\citation{b13}
\citation{b14}
\citation{b15}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-D}}Stochastic Gradient Descent}{4}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-E}}Support Vector Machines}{4}{subsection.3.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Kernel Trick in SVM to perform linear classification on non-linearly separate data}}{4}{figure.caption.4}\protected@file@percent }
\newlabel{fig:svm}{{4}{4}{Kernel Trick in SVM to perform linear classification on non-linearly separate data}{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Prototypical UNet Architecture}}{4}{figure.caption.5}\protected@file@percent }
\newlabel{fig:unet_proto}{{5}{4}{Prototypical UNet Architecture}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-F}}UNet}{4}{subsection.3.6}\protected@file@percent }
\newlabel{sec:aj_unet}{{\mbox  {III-F}}{4}{UNet}{subsection.3.6}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-F}0a}Motivation.}{4}{paragraph.3.6.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-F}0b}Multi-Channel Input Pipeline.}{4}{paragraph.3.6.0.2}\protected@file@percent }
\citation{b16}
\citation{b17}
\citation{b16}
\citation{b17}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces UNet architecture: 8-channel encoder-decoder with skip connections. The contracting path captures context while the expansive path enables precise localisation. Visualisation, courtesy of torchviz \cite  {b16} and Claude \cite  {b17}}}{5}{figure.caption.6}\protected@file@percent }
\newlabel{fig:aj_unet_arch}{{6}{5}{UNet architecture: 8-channel encoder-decoder with skip connections. The contracting path captures context while the expansive path enables precise localisation. Visualisation, courtesy of torchviz \cite {b16} and Claude \cite {b17}}{figure.caption.6}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-F}0c}Network Architecture.}{5}{paragraph.3.6.0.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Training progression showing convergence of combined Dice-Focal loss and IoU metrics over 150 epochs. Post-processing consistently improves validation IoU.}}{5}{figure.caption.7}\protected@file@percent }
\newlabel{fig:training_curves}{{7}{5}{Training progression showing convergence of combined Dice-Focal loss and IoU metrics over 150 epochs. Post-processing consistently improves validation IoU}{figure.caption.7}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-F}0d}Loss Function Design.}{5}{paragraph.3.6.0.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-F}0e}Post-Processing Pipeline.}{5}{paragraph.3.6.0.5}\protected@file@percent }
\citation{b18}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces imperfect ablation studies:  raw predictions → probability thresholding → morphological cleaning}}{6}{figure.caption.8}\protected@file@percent }
\newlabel{fig:postprocessing}{{8}{6}{imperfect ablation studies:\\ raw predictions → probability thresholding → morphological cleaning}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {III-F}0f}Training Configuration.}{6}{paragraph.3.6.0.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {IV}Experimental Results}{6}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {V}Discussion}{6}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-A}}Overview}{6}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-B}}Random Forests}{6}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-C}}SGD}{7}{subsection.5.3}\protected@file@percent }
\newlabel{fig:sgd-train}{{1}{7}{SGD Training}{lstlisting.1}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1}{\ignorespaces SGD Training}}{7}{lstlisting.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-D}}SVM}{7}{subsection.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-E}}CNN}{7}{subsection.5.5}\protected@file@percent }
\citation{b19}
\citation{b20}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-F}}CBAM}{8}{subsection.5.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {V-F}0a}Backbone depth.}{8}{paragraph.5.6.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {V-F}0b}Augmentation intensity.}{8}{paragraph.5.6.0.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-G}}UNet}{8}{subsection.5.7}\protected@file@percent }
\newlabel{sec:aj_unet_discussion}{{\mbox  {V-G}}{8}{UNet}{subsection.5.7}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {V-G}0a}Double Convolution Benefits.}{8}{paragraph.5.7.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {V-G}0b}Connected Components Post-Processing Limitations.}{9}{paragraph.5.7.0.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {V-G}0c}Binary Cross-Entropy Training Instability.}{9}{paragraph.5.7.0.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Training instability with BCE-only loss showing erratic convergence and suboptimal final performance}}{9}{figure.caption.10}\protected@file@percent }
\newlabel{fig:bad_training}{{9}{9}{Training instability with BCE-only loss showing erratic convergence and suboptimal final performance}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {V-G}0d}Performance Comparison: BCE vs. Combined Loss.}{9}{paragraph.5.7.0.4}\protected@file@percent }
\newlabel{fig:bad}{{10a}{9}{BCE loss (IoU 0.12)}{figure.caption.11}{}}
\newlabel{sub@fig:bad}{{a}{9}{BCE loss (IoU 0.12)}{figure.caption.11}{}}
\newlabel{fig:good}{{10b}{9}{Dice + Focal (IoU 0.71)}{figure.caption.11}{}}
\newlabel{sub@fig:good}{{b}{9}{Dice + Focal (IoU 0.71)}{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Segmentation quality comparison: BCE-only training produces sparse predictions (a) whereas the combined Dice–Focal loss yields coherent dead-tree masks (b).}}{9}{figure.caption.11}\protected@file@percent }
\newlabel{fig:loss_comparison}{{10}{9}{Segmentation quality comparison: BCE-only training produces sparse predictions (a) whereas the combined Dice–Focal loss yields coherent dead-tree masks (b)}{figure.caption.11}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {V-G}0e}Parameter Counts.}{9}{paragraph.5.7.0.5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {V-G}0f}Colour Jittering Abandonment.}{9}{paragraph.5.7.0.6}\protected@file@percent }
\bibstyle{IEEEtran}
\bibcite{b1}{1}
\bibcite{b2}{2}
\bibcite{b3}{3}
\bibcite{b4}{4}
\bibcite{b5}{5}
\bibcite{b6}{6}
\bibcite{b7}{7}
\bibcite{b8}{8}
\bibcite{b9}{9}
\bibcite{b10}{10}
\bibcite{b11}{11}
\bibcite{b12}{12}
\bibcite{b13}{13}
\bibcite{b14}{14}
\bibcite{b15}{15}
\bibcite{b16}{16}
\bibcite{b17}{17}
\bibcite{b18}{18}
\bibcite{b19}{19}
\bibcite{b20}{20}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\mbox  {V-G}0g}Final Architecture Performance.}{10}{paragraph.5.7.0.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusion}{10}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {VII}}{10}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{References}{10}{section*.12}\protected@file@percent }
\gdef\svg@ink@ver@settings{{\m@ne }{inkscape}{\m@ne }}
\gdef \@abspage@last{10}
